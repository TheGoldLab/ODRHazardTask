function vals_ = quick5(fits, data)
% function vals_ = quick5(fits, data)
%
% Computes TIME-based Quick (cumulative Weibull)
%   function:
%   
%   0.5 + (0.5 - lambda) * 
%       (1 - exp(-(COH/alpha_t).^beta))
%
%  Where
%   alpha_t = 1./(A1.*TIME.^A2)
%
%  At values in "data":
%       data(1)   ... COH (%)
%       data(2)   ... TIME (sec)
%       data(3)   ... dot dir (-1/1)
%
%   given parameters in "fits":
%       fits(1) ... A1R    (alpha scale, dir = 1)
%       fits(2) ... A1L    (alpha scale, dir = -1)
%       fits(3) ... A2     (allpha exponent)
%       fits(4) ... Beta   (slope)
%       fits(5) ... lambda ("lapse")

% return initial values (init, min, max)
if nargin < 1
    
    vals_ = [ ...
        0.05  0.0001 10;   ...
        0.05  0.0001 10;   ...
        0.8  -5       5;   ...
        1.4   0      10;   ...
        0     0       0.45];

else
    
    alpha = 1./(fits(1).*data(:,2).^fits(3));
    
    
gamma = 0.5 + data(:,3).*guess;
vals_    = 0.5 + (0.5 - fits(5)) .* ...
    (1 - exp(-(data(:,1).* al).^fits(4)));

    p_ = 0.5 + (0.5 - lambda) * (1 - exp( -(x/alpha).^beta )); % quick

    
    R0 = 10;
    times = fits(3).*(1-exp(-(3./fits(3).*data(:,2))));
    S1 = (R0 + fits(1).*data(:,1).^fits(2)).*times;
    S2 = R0.*times;
    
    mu = data(:,3).*fits(4) + (S1-S2);
    sd = sqrt(0.3.*(S1+S2));
    
    % compute pct correct from the dvar
    p = 1 - normcdf(0,mu,sd);
    
    % Avoid NaN's in normcdf, which happens when s=0 (i.e., time=0)
    p(isnan(p)) = 0.5;     % otherwise is NaN
    TINY        = 0.0001;
    p(p<TINY)   = TINY;    % lower bound
    p(p>1-TINY) = 1-TINY;  % upper bound

    % abbott's law
    % for dealing with performance that does not asymptote at 1
    % C = performance at chance
    % D = asymptote as stim -> inf
    % Abbott's law: p* = C + (1 - C - D)P
    % where P is percent correct on [0 ... 1]
    % But remember that the p we just computed is [C ... 1], C = 0.5;
    % i.e., p = C + (1 - C)P
    vals_ = 0.5 + (0.5 - fits(5)).*(2.*p-1);
end
